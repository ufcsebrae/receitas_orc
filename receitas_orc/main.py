"""
main.py

Este √© o ponto de entrada principal para o pipeline de processamento de
receitas or√ßament√°rias. Ele orquestra a execu√ß√£o do pipeline chamando
os servi√ßos apropriados em uma sequ√™ncia l√≥gica.
"""
import logging
import pandas as pd
import numpy as np

# Importa√ß√µes do seu projeto
from receitas_orc.config.mdx_setup import setup_mdx_environment
from receitas_orc.services.global_services import selecionar_consulta_por_nome
from receitas_orc.services.dataframe_processing import renomear_colunas_padrao
from receitas_orc.services import pipeline_service

# --- Configura√ß√µes Globais ---
# ATEN√á√ÉO: Substitua pelo caminho EXATO e REAL da sua DLL.
# Use o m√©todo "Shift + Bot√£o Direito > Copiar como caminho" para obter o caminho.
DLL_PATH = r"C:\Microsoft.AnalysisServices.AdomdClient.dll"
RESULT_FILE_NAME = "resultado_pipeline.xlsx"

# --- Configura√ß√£o de Logging ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)


def executar_pipeline():
    """Orquestra a execu√ß√£o do pipeline de dados."""
    logger.info("üöÄ Iniciando pipeline de execu√ß√£o...")
    
    try:
        setup_mdx_environment(DLL_PATH)
        logger.info("Ambiente MDX inicializado com sucesso.")
    except Exception as e:
        logger.error(f"‚ùå Falha cr√≠tica ao inicializar ambiente MDX: {e}", exc_info=True)
        return

    # Etapa 1: Carregar e preparar dados brutos
    logger.info("--- Etapa 1: Carregando dados brutos ---")
    resultados = selecionar_consulta_por_nome("RECEITAS_ORCADAS_2025, cc, acoes, FatoFechamento")
    df_orcadas = resultados.get("RECEITAS_ORCADAS_2025")
    df_acoes = resultados.get("acoes")
    df_cc = resultados.get("cc")
    df_FatoFechamento = resultados.get("FatoFechamento")
    
    if any(df is None or df.empty for df in [df_orcadas, df_acoes, df_cc]):
        logger.error("Falha ao carregar DataFrames essenciais (orcadas, acoes, cc). Encerrando.")
        return

    logger.info("Renomeando colunas...")
    df_orcadas = renomear_colunas_padrao(df_orcadas)
    df_acoes = renomear_colunas_padrao(df_acoes)
    df_cc = renomear_colunas_padrao(df_cc)
    if df_FatoFechamento is not None:
        # A nova consulta SQL para FatoFechamento j√° define os nomes corretos,
        # ent√£o a renomea√ß√£o pode n√£o ser mais necess√°ria para ele.
        # df_FatoFechamento = renomear_colunas_padrao(df_FatoFechamento)
        pass


    # Etapa 2: Obter o m√™s do usu√°rio
    logger.info("--- Etapa 2: Obtendo m√™s de refer√™ncia ---")
    mes_selecionado = pipeline_service.obter_mes_do_usuario()
    if mes_selecionado is None:
        logger.warning("Nenhum m√™s v√°lido selecionado. Encerrando o pipeline.")
        return

    # Etapa 3: Filtrar os dados de origem pelo m√™s selecionado
    logger.info(f"--- Etapa 3: Filtrando dados para o m√™s {mes_selecionado} ---")
    df_despesas_do_mes = pipeline_service.filtrar_dataframe_por_mes(df_acoes, mes_selecionado, "Despesas")
    df_receitas_do_mes = pipeline_service.filtrar_dataframe_por_mes(df_orcadas, mes_selecionado, "Receitas")
    
    df_fechamento_do_mes = pd.DataFrame() # Inicia vazio
    if df_FatoFechamento is not None and not df_FatoFechamento.empty:
        # A fun√ß√£o de filtro precisa ser ajustada para a coluna 'DATA' de FatoFechamento
        logger.info(f"Filtrando 'FatoFechamento' pela coluna 'DATA' para o m√™s: {mes_selecionado}")
        df_FatoFechamento['DATA'] = pd.to_datetime(df_FatoFechamento['DATA'], errors='coerce')
        df_fechamento_do_mes = df_FatoFechamento[df_FatoFechamento['DATA'].dt.month == mes_selecionado]
    else:
        logger.warning("'FatoFechamento' n√£o foi carregado ou est√° vazio. Pulando esta etapa.")

    # Etapa 4: Processar os dados j√° filtrados
    logger.info("--- Etapa 4: Processando e juntando dados ---")
    df_acoes_agg = pipeline_service.agregar_despesas_por_acao(df_despesas_do_mes)
    df_acoes_ranqueadas = pipeline_service.ranquear_acoes_e_juntar_cc(df_acoes_agg, df_cc)
    
    # Junta com receitas e fechamento ANTES de apropriar a receita
    df_com_receitas = pipeline_service.juntar_com_receitas(df_acoes_ranqueadas, df_receitas_do_mes)
    df_intermediario = pipeline_service.juntar_com_fato_fechamento(df_com_receitas, df_fechamento_do_mes)

    # Etapa 5: Aplicar regra de neg√≥cio final
    logger.info("--- Etapa 5: Aplicando regra de apropria√ß√£o de receita ---")
    df_resultado_final = pipeline_service.aplicar_apropriacao_de_receita(df_intermediario)
    
    # Etapa 6: Apresentar e salvar o resultado
    logger.info("--- Etapa 6: Gerando sa√≠da ---")
    logger.info("‚úÖ Pipeline executado com sucesso.")
    print("\nüìä Resultado final:\n")
    print(df_resultado_final)
    df_resultado_final.to_excel(RESULT_FILE_NAME, index=False)
    logger.info(f"üìÅ Resultado exportado para '{RESULT_FILE_NAME}' com sucesso.")

def main():
    """Fun√ß√£o principal para iniciar a execu√ß√£o do pipeline."""
    executar_pipeline()

if __name__ == "__main__":
    main()
